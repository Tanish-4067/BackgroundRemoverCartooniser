{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pycocotools","execution_count":5,"outputs":[{"output_type":"stream","text":"Collecting pycocotools\n  Downloading pycocotools-2.0.2.tar.gz (23 kB)\nRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (49.6.0.post20201009)\nRequirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.21)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.3.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (7.2.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.19.5)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\nBuilding wheels for collected packages: pycocotools\n  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=272642 sha256=45a110cfeeb38bc90c15b757960e1b5fa48245ad7e48ddd3eb0bc4dc4ee50965\n  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\nSuccessfully built pycocotools\nInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.2\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycocotools.coco import COCO\nimport numpy as np\nimport skimage.io as io\nimport random\nimport os\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n### For visualizing the outputs ###\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDir= '../input/coco-2017-dataset/coco2017'\ndataType='train2017'\nannFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the COCO api for instance annotations\ncoco=COCO(annFile)\n\n# Load the categories in a variable\ncatIDs = coco.getCatIds()\ncats = coco.loadCats(catIDs)\n\nprint(cats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getClassName(classID, cats):\n    for i in range(len(cats)):\n        if cats[i]['id']==classID:\n            return cats[i]['name']\n    return \"None\"\nprint('The class name is', getClassName(76, cats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the classes (out of the 81) which you want to see. Others will not be shown.\nfilterClasses = ['person']\n\n# Fetch class IDs only corresponding to the filterClasses\ncatIds = coco.getCatIds(catNms=filterClasses) \n# Get all images containing the above Category IDs\nimgIds = coco.getImgIds(catIds=catIds)\nprint(\"Number of images containing all the  classes:\", len(imgIds))\n\n# load and display a random image\nimg = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\nI = io.imread('{}//{}/{}'.format(dataDir,dataType,img['file_name']))/255.0\n\nplt.axis('off')\nplt.imshow(I)\nplt.show()\n\nI.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load and display instance annotations\nplt.imshow(I)\nplt.axis('off')\nannIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\nanns = coco.loadAnns(annIds)\ncoco.showAnns(anns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## ALl POSSIBLE COMBINATIONS ########\nclasses = ['person']\n\nimages = []\nif classes!=None:\n    # iterate for each individual class in the list\n    for className in classes:\n        # get all images containing given class\n        catIds = coco.getCatIds(catNms=className)\n        imgIds = coco.getImgIds(catIds=catIds)\n        images += coco.loadImgs(imgIds)\nelse:\n    imgIds = coco.getImgIds()\n    images = coco.loadImgs(imgIds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, filter out the repeated images    \nunique_images = []\nfor i in range(len(images)):\n    if images[i] not in unique_images:\n        unique_images.append(images[i])\n\ndataset_size = len(unique_images)\n\nprint(\"Number of images containing the filter classes:\", dataset_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### GENERATE A SEGMENTATION MASK ####\nfilterClasses = ['person']\nmask = np.zeros((img['height'],img['width']))\nfor i in range(len(anns)):\n    className = getClassName(anns[i]['category_id'], cats)\n    pixel_value = filterClasses.index(className)+1\n    mask = np.maximum(coco.annToMask(anns[i])*pixel_value, mask)\nplt.imshow(mask)\n\n#### GENERATE A BINARY MASK ####\nmask = np.zeros((img['height'],img['width']))\nfor i in range(len(anns)):\n    mask = np.maximum(coco.annToMask(anns[i]), mask)\nplt.imshow(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def filterDataset(folder, classes=None, mode = 'train'):    \n    # initialize COCO api for instance annotations\n    annFile = '{}/annotations/instances_{}.json'.format(folder, mode)\n    coco = COCO(annFile)\n    \n    images = []\n    if classes!=None:\n        # iterate for each individual class in the list\n        for className in classes:\n            # get all images containing given categories\n            catIds = coco.getCatIds(catNms=className)\n            imgIds = coco.getImgIds(catIds=catIds)\n            images += coco.loadImgs(imgIds)\n    \n    else:\n        imgIds = coco.getImgIds()\n        images = coco.loadImgs(imgIds)\n    \n    # Now, filter out the repeated images\n    unique_images = []\n    for i in range(len(images)):\n        if images[i] not in unique_images:\n            unique_images.append(images[i])\n            \n    random.shuffle(unique_images)\n    dataset_size = len(unique_images)\n    \n    return unique_images, dataset_size, coco","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getClassName(classID, cats):\n    for i in range(len(cats)):\n        if cats[i]['id']==classID:\n            return cats[i]['name']\n    return None\n\ndef getImage(imageObj, img_folder, input_image_size):\n    # Read and normalize an image\n    train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n    # Resize\n    train_img = cv2.resize(train_img, input_image_size)\n    if (len(train_img.shape)==3 and train_img.shape[2]==3): # If it is a RGB 3 channel image\n        return train_img\n    else: # To handle a black and white image, increase dimensions to 3\n        stacked_img = np.stack((train_img,)*3, axis=-1)\n        return stacked_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getNormalMask(imageObj, classes, coco, catIds, input_image_size):\n    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n    anns = coco.loadAnns(annIds)\n    cats = coco.loadCats(catIds)\n    train_mask = np.zeros(input_image_size)\n    for a in range(len(anns)):\n        className = getClassName(anns[a]['category_id'], cats)\n        pixel_value = classes.index(className)+1\n        new_mask = cv2.resize(coco.annToMask(anns[a])*pixel_value, input_image_size)\n        train_mask = np.maximum(new_mask, train_mask)\n\n    # Add extra dimension for parity with train_img size [X * X * 3]\n    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n    return train_mask  \n    \ndef getBinaryMask(imageObj, coco, catIds, input_image_size):\n    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n    anns = coco.loadAnns(annIds)\n    train_mask = np.zeros(input_image_size)\n    for a in range(len(anns)):\n        new_mask = cv2.resize(coco.annToMask(anns[a]), input_image_size)\n#Threshold because resizing may cause extraneous values\n        new_mask[new_mask >= 0.5] = 1\n        new_mask[new_mask < 0.5] = 0\n\n        train_mask = np.maximum(new_mask, train_mask)\n\n    # Add extra dimension for parity with train_img size [X * X * 3]\n    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n    return train_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataGeneratorCoco(images, classes, coco, folder, \n                      input_image_size=(224,224), batch_size=4, mode='train', mask_type='binary'):\n    \n    img_folder = '{}//{}'.format(folder, mode)\n    dataset_size = len(images)\n    catIds = coco.getCatIds(catNms=classes)\n    \n    c = 0\n    while(True):\n        img = np.zeros((batch_size, input_image_size[0], input_image_size[1], 3)).astype('float')\n        mask = np.zeros((batch_size, input_image_size[0], input_image_size[1], 1)).astype('float')\n\n        for i in range(c, c+batch_size): #initially from 0 to batch_size, when c = 0\n            imageObj = images[i]\n            \n            ### Retrieve Image ###\n            train_img = getImage(imageObj, img_folder, input_image_size)\n            \n            ### Create Mask ###\n            if mask_type==\"binary\":\n                train_mask = getBinaryMask(imageObj, coco, catIds, input_image_size)\n            \n            elif mask_type==\"normal\":\n                train_mask = getNormalMask(imageObj, classes, coco, catIds, input_image_size)                \n            \n            # Add to respective batch sized arrays\n            img[i-c] = train_img\n            mask[i-c] = train_mask\n            \n        c+=batch_size\n        if(c + batch_size >= dataset_size):\n            c=0\n            random.shuffle(images)\n        yield img, mask\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualizeGenerator(gen):\n    # Iterate the generator to get image and mask batches\n    img, mask = next(gen)\n \n    fig = plt.figure(figsize=(20, 10))\n    outerGrid = gridspec.GridSpec(1, 2, wspace=0.1, hspace=0.1)\n   \n    for i in range(2):        \n        innerGrid = gridspec.GridSpecFromSubplotSpec(2, 2, subplot_spec=outerGrid[i], wspace=0.05, hspace=0.05)\n\n        for j in range(4):\n            ax = plt.Subplot(fig, innerGrid[j])\n            if(i==1):\n                ax.imshow(img[j]);\n            else:\n                ax.imshow(mask[j][:,:,0]);\n                \n            ax.axis('off')\n            fig.add_subplot(ax)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augmentationsGenerator(gen, augGeneratorArgs, seed=None):\n    # Initialize the image data generator with args provided\n    image_gen = ImageDataGenerator(**augGeneratorArgs)\n    \n    # Remove the brightness argument for the mask. Spatial arguments similar to image.\n    augGeneratorArgs_mask = augGeneratorArgs.copy()\n    _ = augGeneratorArgs_mask.pop('brightness_range', None)\n    # Initialize the mask data generator with modified args\n    mask_gen = ImageDataGenerator(**augGeneratorArgs_mask)\n    \n    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n    \n    for img, mask in gen:\n        seed = np.random.choice(range(9999))\n        # keep the seeds syncronized otherwise the augmentation of the images \n        # will end up different from the augmentation of the masks\n        g_x = image_gen.flow(255*img, \n                             batch_size = img.shape[0], \n                             seed = seed, \n                             shuffle=True)\n        g_y = mask_gen.flow(mask, \n                             batch_size = mask.shape[0], \n                             seed = seed, \n                             shuffle=True)\n        \n        img_aug = next(g_x)/255.0\n        mask_aug = next(g_y)\n                   \n        yield img_aug, mask_aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\naugGeneratorArgs = dict(featurewise_center = False, \n                        samplewise_center = False,\n                        rotation_range = 5, \n                        width_shift_range = 0.01, \n                        height_shift_range = 0.01, \n                        brightness_range = (0.8,1.2),\n                        shear_range = 0.01,\n                        zoom_range = [1, 1.25],  \n                        horizontal_flip = True, \n                        vertical_flip = False,\n                        fill_mode = 'reflect',\n                        data_format = 'channels_last')\n\n# Call the function with the arguments\n# aug_gen = augmentationsGenerator(val_gen, augGeneratorArgs)\n\n# visualizeGenerator(aug_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from zipfile import ZipFile\n# file_name1=\"stuff_annotations_trainval2017.zip\"\n# file_name2=\"train2017.zip\"\n# file_name3=\"val2017.zip\"\n# file_name4=\"annotations_trainval2017.zip\"\n# with ZipFile(file_name2 ,'r') as zip:\n#   zip.extractall()\n#   print('yep')\n# folder = '../input/coco-2017-dataset/coco2017'\n# classes = ['person']\n# mode = 'train2017'\n# images, dataset_size, coco = filterDataset(folder, classes, mode)\n# batch_size = 4\n# input_image_size = (224,224)\n# mask_type = 'binary'\n\n# val_gen = dataGeneratorCoco(images, classes, coco, folder, \n#                             input_image_size, batch_size, mode, mask_type)\n\n\n\n\n# visualizeGenerator(val_gen)\n\n\n\nfolder = '../input/coco-2017-dataset/coco2017'\nclasses = ['person']\ntr_mode = 'train2017'\n\ntrain_images, tr_dataset_size, tr_coco = filterDataset(folder, classes, tr_mode)\n\nfolder = '../input/coco-2017-dataset/coco2017'\nclasses = ['person']\nval_mode = 'val2017'\n\nval_images, v_dataset_size, v_coco = filterDataset(folder, classes, val_mode)\n\nbatch_size = 4\ninput_image_size = (224,224)\nmask_type = 'binary'\n\ntrain_gen = dataGeneratorCoco(train_images, classes, tr_coco, folder, \n                            input_image_size, batch_size, tr_mode, mask_type)\nvalid_gen = dataGeneratorCoco(val_images, classes, v_coco, folder, \n                            input_image_size, batch_size, val_mode, mask_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making Unet architecture\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.models import Model\n\ndef conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef encoder_block(input, num_filters):\n    x = conv_block(input, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p\n\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n\ndef build_unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"U-Net\")\n    return model\n\nif __name__ == \"__main__\":\n    input_shape = (224, 224, 3)\n    model = build_unet(input_shape)\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_steps = len(train_images)/batch_size\nvalid_steps = len(val_images)/batch_size\nepochs = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_aug_gen = augmentationsGenerator(train_gen, augGeneratorArgs)\nval_aug_gen = augmentationsGenerator(valid_gen, augGeneratorArgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\ncheckpoint_path = \"./unitseg.ckpt\"\ncp_callback = ModelCheckpoint(\n    filepath=checkpoint_path, \n    verbose=1, \n    save_weights_only=True,\n    save_freq=8000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch = train_steps, validation_steps=valid_steps, epochs = epochs)\nhistory = model.fit(x = train_gen,\n                validation_data = valid_gen,\n                steps_per_epoch = train_steps,\n                validation_steps = valid_steps,\n                epochs = epochs,\n                callbacks=[cp_callback],\n                verbose = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"UnetSegmentation2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"Unet_model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":8,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}